# -*- coding: utf-8 -*-
"""new_final__run_6_mer_sub_classes_semi_exception_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B0rEbQSSdSOtHQ9CXgE3UYIv6Kmv3sJk
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set(style="darkgrid")
import os
import glob as gb
import cv2
import tensorflow as tf
import keras
import time
import pickle
import itertools
from inspect import signature
from keras.utils import plot_model,to_categorical
from keras.models import Model, load_model
from keras.layers import Input,Flatten,concatenate,Add,Embedding,Dense,Activation,Dropout,BatchNormalization
from keras.layers import Conv2D,SeparableConv2D,MaxPooling2D,GlobalAveragePooling2D,ReLU
from keras.optimizers import Adam
from keras import regularizers
from keras import initializers
from keras.metrics import categorical_crossentropy
from keras.callbacks import EarlyStopping, ModelCheckpoint
from inspect import signature
from sklearn.metrics import classification_report, precision_score, roc_auc_score, f1_score, recall_score
from sklearn.metrics import precision_recall_curve, average_precision_score, matthews_corrcoef, balanced_accuracy_score
from sklearn.metrics import confusion_matrix, accuracy_score,cohen_kappa_score,log_loss,roc_curve,auc

from google.colab import drive
drive.mount('/content/drive')

BASE_FILE = "/content/drive/MyDrive/new_6mer_sub_splitted"
train_file="{0}/train/".format(BASE_FILE)
test_file="{0}/val/".format(BASE_FILE)

for folder in  os.listdir(train_file):
    files = gb.glob(pathname= str( train_file + folder+'/*.png'))
    print(f'For training data , found {len(files)} in folder {folder}')

for folder in  os.listdir(test_file) :
    files = gb.glob(pathname= str( test_file + folder + '/*.png'))
    print(f'For testing data , found {len(files)} in folder {folder}')

code = {'Adrenergic':0,'Amine':1,'Anaphylatoxin':2,'BOSS':3,'BrainSpec':4 ,'Cadherin':5,'Calcitonin':6,'cAMP':7,'Cannabinoid':8,'ClacSense':9 ,
        'Corticotropin':10,'EMR1':11,'GABA':12,'Gastric':13,'Glucagon':14,'GlutaMeta':15,'GRHR':16,'GrowthHorm':17,'Hormone':18,
        'Interleukin8':19,'Latrophilin':20,'Leuko':21,'Lyso':22,'Melaton':23,'Methuselah':24,'Nucleotide':25,'Olfactory':26,'PACAP':27,
        'Parathyroid':28,'Peptide':29,'Pheromone':30,'Platelet':31,'Prostanoid':32,'Secretin':33,'Taste':34,'Thyro':35,'Vasocactive':36}
def getcode(n) :
  for x , y in code.items() :
        if n == y :
            return x

size = []
for folder in  os.listdir(train_file) :
    files = gb.glob(pathname= str( train_file + folder + '/*.png'))
    for file in files:
      image = plt.imread(file)
      size.append(image.shape)
pd.Series(size).value_counts()

s = 224
X_train = []
y_train = []
for folder in  os.listdir(train_file) :
    files = gb.glob(pathname= str(train_file + folder + '/*.png'))
    for file in files:
        image = cv2.imread(file)
        image_array = cv2.resize(image , (s,s))
        X_train.append(list(image_array))
        y_train.append(code[folder])

X_test = []
y_test = []
for folder in  os.listdir(test_file) :
    files = gb.glob(pathname= str(test_file + folder + '/*.png'))
    for file in files:
        image = cv2.imread(file)
        image_array = cv2.resize(image , (s,s))
        X_test.append(list(image_array))
        y_test.append(code[folder])

X_train = np.array(X_train)
X_test = np.array(X_test)
y_train = np.array(y_train)
y_test = np.array(y_test)
print(f'X_train shape  is {X_train.shape}')
print(f'X_test shape  is {X_test.shape}')
print(f'y_train shape  is {y_train.shape}')
print(f'y_test shape  is {y_test.shape}')



def conv_bn(x,filters,kernel_size,strides=1):
    x=Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding='same',use_bias=True)(x)
    x=BatchNormalization()(x)
    return x


input_image=Input(shape=(s,s,3))
x=conv_bn(input_image,filters=100,kernel_size=3,strides=2)
x=ReLU()(x)
x=conv_bn(x,filters=100,kernel_size=3)
tensor=ReLU()(x)

x=conv_bn(tensor,filters=100,kernel_size=3)
x=ReLU()(x)
x=conv_bn(x,filters=100,kernel_size=3)
x=MaxPooling2D(pool_size=2,strides=1,padding='same')(x)
x=conv_bn(x,filters=100,kernel_size=3)
x=MaxPooling2D(pool_size=2,strides=1,padding='same')(x)
x=conv_bn(x,filters=100,kernel_size=3)
x=MaxPooling2D(pool_size=2,strides=1,padding='same')(x)


tensor=conv_bn(tensor,filters=100,kernel_size=1,strides=1)
x=Add()([tensor,x])
x=ReLU()(x)
x=conv_bn(x,filters=40,kernel_size=3)
x=ReLU()(x)
x=conv_bn(x,filters=40,kernel_size=3)
x=MaxPooling2D(pool_size=2,strides=1,padding='same')(x)

tensor=conv_bn(tensor,filters=40,kernel_size=1,strides=1)
x=Add()([tensor,x])
x=ReLU()(x)
x=conv_bn(x,filters=20,kernel_size=3)
x=ReLU()(x)
x=conv_bn(x,filters=20,kernel_size=3)
x=MaxPooling2D(pool_size=2,strides=2,padding='same')(x)
x=conv_bn(x,filters=20,kernel_size=3)
x=ReLU()(x)
x=MaxPooling2D(pool_size=2,strides=2,padding='same')(x)
x=Flatten()(x)
x=Dense(2000,activation='relu')(x)
x=BatchNormalization()(x)
output = Dense(37,activation='softmax')(x)
new_6_mer_sub_families = Model(inputs=input_image, outputs=output)

print('Model Details are : ')
print(new_6_mer_sub_families.summary())

plot_model(new_6_mer_sub_families, to_file='new_6_mer_sub_families.png', show_shapes=True)

new_6_mer_sub_families.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.00001), metrics=['accuracy'])

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)
mc = ModelCheckpoint('new_6_mer_sub_families.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)

history = new_6_mer_sub_families.fit(X_train, y_train,validation_data=(X_test, y_test), batch_size=32, epochs=40, verbose=1,callbacks=[es, mc])

new_6_mer_sub_families.save("new_6_mer_sub_families.h5")

saved_model = load_model('new_6_mer_sub_families.h5')

train_loss, train_acc = saved_model.evaluate(X_train, y_train, verbose=0)
test_loss,test_acc = saved_model.evaluate(X_test, y_test, verbose=0)
print('Train Acc: %.3f, Test Acc: %.3f' % (train_acc * 100, test_acc * 100))
print('Train Loss : %.3f . Test Loss : %.3f' % (test_loss, test_acc))

start_time = time.time() #Prediction start time

predictions= saved_model.predict(X_test)
np.save('new_6_mer_sub_families_prediction.npy', predictions)
y_pred=np.argmax(predictions,axis=1)
labels_test=to_categorical(y_test)
np.save('new_y_true_6_mer_sub_families_one_hot_encoded.npy', labels_test)
print('Prediction Shape is {}'.format(y_pred.shape))

print('Prediction Shape is {}'.format(predictions.shape))

end_time = time.time()  # CNN_1 end time
print('Prediction Time taken = ', (end_time - start_time), 'seconds')

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()



# Plot history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

print(classification_report(y_test,y_pred))

mcc_val = matthews_corrcoef(y_test,y_pred)
bacc_val = balanced_accuracy_score(y_test,y_pred)
print("mathew's correlation coefficient = %.5f" % (mcc_val))
print("Balanced Accuracy = %.5f" % (bacc_val))

def plot_confusion_matrix(cm,classes,normalize=False,title='confusion_matrix',cmap=plt.cm.Blues):
    if normalize:
        cm=cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print('Normalized Confusion Matrix')
    else:
        print('Confusion_Matrix, without Normalization')

    plt.imshow(cm,interpolation='nearest',cmap=cmap)
    plt.title(title,weight='bold',fontsize=16)
    tick_marks=np.arange(len(classes))
    plt.xticks(tick_marks,classes,fontsize=14)
    plt.yticks(tick_marks,classes,fontsize=14)

    fmt='.2f' if normalize else 'd'
    thresh=cm.max() / 2.
    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j,i,format(cm[i,j],fmt),horizontalalignment="center",
                 fontsize=12,weight='bold',color="white" if cm[i,j]>thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label',fontsize=16,weight='bold')
    plt.xlabel('Predicted label',fontsize=16,weight='bold')

#compute confusion matrix
cnf_mtx=confusion_matrix(y_test,y_pred)
np.set_printoptions(precision=2)

#plot non-normalized confusion matrix
plt.figure(figsize=(10,10))
plot_confusion_matrix(cnf_mtx,classes=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37],normalize=False,title='Non_Normalized confusion_matrix',cmap=plt.cm.Blues)
plt.show()

coh_kap=cohen_kappa_score(y_test,y_pred)
print("cohen_kappa_socre= %.5f" % (coh_kap))

n_classes = 37
#print(n_classes)

# For each class
precision = dict()
recall = dict()
average_precision = dict()
for i in range(n_classes):
    precision[i], recall[i], _ = precision_recall_curve(labels_test[:, i],
                                                        predictions[:, i])
    average_precision[i] = average_precision_score(labels_test[:, i], predictions[:, i])

# A "micro-average": quantifying score on all classes jointly
precision["micro"], recall["micro"], _ = precision_recall_curve(labels_test.ravel(),
    predictions.ravel())
average_precision["micro"] = average_precision_score(labels_test, predictions,
                                                     average="micro")
print('Average precision score, micro-averaged over all classes: {0:0.5f}'
      .format(average_precision["micro"]))

"""Ploting precision-recall curve"""
# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument
step_kwargs = ({'step': 'post'}if 'step' in signature(plt.fill_between).parameters else {})
plt.figure()
plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2,where='post')

#plt.fill_between(recall["micro"], precision["micro"], alpha=0.2, color='b', #**step_kwargs)

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title('Average precision score, micro-averaged over all classes: AP={0:0.5f}' .format(average_precision["micro"]))
plt.show()
#plt.savefig('PR_curve_DeepPff.png')

roc_score=roc_auc_score( labels_test, predictions, average="weighted", multi_class="ovr" )
print("ROC AUC score= %.5f" % (roc_score))

fpr1 , tpr1, thresholds1 = roc_curve(labels_test.ravel(), predictions.ravel())
plt.plot(fpr1, tpr1, label= "AUC={:.5f}".format(auc(fpr1,tpr1)))
plt.legend()
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.title('Receiver Operating Characteristic')
plt.show()

fpr = dict()
tpr = dict()
roc_auc=dict()
for i in range(10):
    fpr[i], tpr[i], _ = roc_curve(labels_test[:, i],predictions[:, i])
    roc_auc[i]=auc(fpr[i],tpr[i])
    plt.plot(fpr[i], tpr[i], lw=2, label='class {} , AUC={:.3f}'.format(i, roc_auc[i]))

plt.xlabel("FPR")
plt.ylabel("TPR")
plt.title('Receiver Operating Characteristic')
plt.legend(loc="best")
plt.show()