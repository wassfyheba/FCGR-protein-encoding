# -*- coding: utf-8 -*-
"""new_ final_run_3_mer_trial_classes_semi_exception_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17QwftRfrpH-fjbDGZHA41tlgfQiEfjJX
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set(style="darkgrid")
import os
import glob as gb
import cv2
import tensorflow as tf
import keras
import time
import pickle
import itertools
from inspect import signature
from keras.utils import plot_model,to_categorical
from keras.models import Model, load_model
from keras.layers import Input,Flatten,concatenate,Add,Embedding,Dense,Activation,Dropout,BatchNormalization
from keras.layers import Conv2D,SeparableConv2D,MaxPooling2D,GlobalAveragePooling2D,ReLU
from keras.optimizers import Adam
from keras import regularizers
from keras import initializers
from keras.metrics import categorical_crossentropy
from keras.callbacks import EarlyStopping, ModelCheckpoint
from inspect import signature
from sklearn.metrics import classification_report, precision_score, roc_auc_score, f1_score, recall_score
from sklearn.metrics import precision_recall_curve, average_precision_score, matthews_corrcoef, balanced_accuracy_score
from sklearn.metrics import confusion_matrix, accuracy_score,cohen_kappa_score,log_loss,roc_curve,auc

from google.colab import drive
drive.mount('/content/drive')

BASE_FILE = "/content/drive/MyDrive/new_3mer_family_splitted"
train_file="{0}/train/".format(BASE_FILE)
test_file="{0}/val/".format(BASE_FILE)

for folder in  os.listdir(train_file):
    files = gb.glob(pathname= str( train_file + folder+'/*.png'))
    print(f'For training data , found {len(files)} in folder {folder}')

for folder in  os.listdir(test_file) :
    files = gb.glob(pathname= str( test_file + folder + '/*.png'))
    print(f'For testing data , found {len(files)} in folder {folder}')

code = {'class_A':0 ,'class_B':1,'class_C':2,'class_D':3,'class_E':4,}
def getcode(n) :
  for x , y in code.items() :
        if n == y :
            return x

s = 224
X_train = []
y_train = []
for folder in  os.listdir(train_file) :
    files = gb.glob(pathname= str(train_file + folder + '/*.png'))
    for file in files:
        image = cv2.imread(file)
        image_array = cv2.resize(image , (s,s))
        X_train.append(list(image_array))
        y_train.append(code[folder])

# prompt: normalize the images also convert the labels by one hot encoding

y_train = to_categorical(y_train, num_classes=len(code))  # One-hot encode the labels

X_test = []
y_test = []
for folder in  os.listdir(test_file) :
    files = gb.glob(pathname= str(test_file + folder + '/*.png'))
    for file in files:
        image = cv2.imread(file)
        image_array = cv2.resize(image , (s,s))
        X_test.append(list(image_array))
        y_test.append(code[folder])

y_test = to_categorical(y_test, num_classes=len(code))

X_train = np.array(X_train)
X_test = np.array(X_test)
y_train = np.array(y_train)
y_test = np.array(y_test)
print(f'X_train shape  is {X_train.shape}')
print(f'X_test shape  is {X_test.shape}')
print(f'y_train shape  is {y_train.shape}')
print(f'y_test shape  is {y_test.shape}')

np.save('x_train_3mer_families_resized.npy', X_train)
np.save('x_test_3mer_families_resized.npy', X_test)
np.save('y_train_3mer_families_resized.npy', y_train)
np.save('y_test_3mer_families_resized.npy', y_test)

from sklearn.model_selection import StratifiedKFold

def conv_bn(x,filters,kernel_size,strides=1):
    x=Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding='same',use_bias=True)(x)
    x=BatchNormalization()(x)
    return x

def create_model(input_shape, num_classes):
    input_image = Input(shape=input_shape)
    x = conv_bn(input_image, filters=100, kernel_size=3, strides=2)
    x = ReLU()(x)
    x = conv_bn(x, filters=100, kernel_size=3)
    tensor = ReLU()(x)

    x = conv_bn(tensor, filters=100, kernel_size=3)
    x = ReLU()(x)
    x = conv_bn(x, filters=100, kernel_size=3)
    x = MaxPooling2D(pool_size=2, strides=1, padding='same')(x)
    x = conv_bn(x, filters=100, kernel_size=3)
    x = MaxPooling2D(pool_size=2, strides=1, padding='same')(x)
    x = conv_bn(x, filters=100, kernel_size=3)
    x = MaxPooling2D(pool_size=2, strides=1, padding='same')(x)

    tensor = conv_bn(tensor, filters=100, kernel_size=1, strides=1)
    x = Add()([tensor, x])
    x = ReLU()(x)
    x = conv_bn(x, filters=40, kernel_size=3)
    x = ReLU()(x)
    x = conv_bn(x, filters=40, kernel_size=3)
    x = MaxPooling2D(pool_size=2, strides=1, padding='same')(x)

    tensor = conv_bn(tensor, filters=40, kernel_size=1, strides=1)
    x = Add()([tensor, x])
    x = ReLU()(x)
    x = conv_bn(x, filters=20, kernel_size=3)
    x = ReLU()(x)
    x = conv_bn(x, filters=20, kernel_size=3)
    x = MaxPooling2D(pool_size=2, strides=2, padding='same')(x)
    x = conv_bn(x, filters=20, kernel_size=3)
    x = ReLU()(x)
    x = MaxPooling2D(pool_size=2, strides=2, padding='same')(x)
    x = Flatten()(x)
    x = Dense(2000, activation='relu')(x)
    x = BatchNormalization()(x)
    output = Dense(num_classes, activation='softmax')(x)
    model = Model(inputs=input_image, outputs=output)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)

# 5-fold cross-validation
fold_no = 1
k = 5
skf = StratifiedKFold(n_splits=k, shuffle=True)
for train_index, val_index in skf.split(X_train, np.argmax(y_train, axis=1)):
    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index] # Use temporary variables for fold data
    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]

    # Create and train the model
    model = create_model(input_shape=(224, 224, 3), num_classes=5)
    model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=25, batch_size=32,callbacks=[es])


 # Evaluate the model
    scores = model.evaluate(X_val_fold, y_val_fold, verbose=0) # Evaluate on the validation data for the fold
    print(f"Fold {fold_no} - Loss: {scores[0]}, Accuracy: {scores[1]}")
    fold_no += 1



